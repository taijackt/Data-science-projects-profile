{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Dog breed classification using Pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the tools we need\nimport os \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/dog-breed-identification/labels.csv')\ntest_df = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare for training set and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training df\n\ntrain_path = train_df.id.tolist()\ntrain_path = [image+'.jpg' for image in train_path]\ntrain_dir = '../input/dog-breed-identification/train'\ntrain_path = [os.path.join(train_dir,dog_name) for dog_name in train_path]\ntrain_df['path'] = train_path\ntrain_df.drop('id',axis=1, inplace=True)\n\n# Label encoding the breed column\ntrain_df['breed_label'] = LabelEncoder().fit_transform(train_df['breed'])\n\n# Store the id and breed for result checking\nmatch_id_df = train_df.copy()\nmatch_id_df.drop('path',axis=1,inplace=True)\n\n# drop the breed column\ntrain_df.drop('breed',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing df\ntest_df = test_df[['id']]\nanswer_df = test_df.copy()\ntest_path = test_df.id.tolist()\ntest_path = [name+'.jpg' for name in test_path]\ntest_dir = '../input/dog-breed-identification/test'\ntest_path = [os.path.join(test_dir,name) for name in test_path]\ntest_df = pd.DataFrame(test_path,columns=['path'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create custom dataset module"},{"metadata":{"trusted":true},"cell_type":"code","source":"# input the tools we need\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom Data class\nclass Dog_data(nn.Module):\n    def __init__(self, csv_file, transform=None, test=False):\n        self.transform = transform\n        self.data = csv_file\n        self.len = self.data.shape[0]\n        self.test = test\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self,index):\n        img_path = self.data.iloc[index,0]\n        if self.test==False:\n            label = self.data.iloc[index,1]\n    \n        open_image = Image.open(img_path)\n        \n        if self.transform:\n            open_image = self.transform(open_image)\n        \n        if self.test==False: \n            return open_image, label\n        elif self.test==True:\n            return open_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split into training set and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use 30% of the data to be validation set\nval_size = round(train_df.shape[0]*0.3)\n\n# Shuffle the dataset\ntrain_df = train_df.sample(frac=1)\n\n# split into train and val\nvalidation_df = train_df.iloc[:val_size,:]\ntraining_df = train_df.iloc[val_size:,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create training set and validation set\n- Since I will use the pretrained model, the image must be normalized in the same way.\n- Size: 224 x 224\n- Then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225] "},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = [0.485, 0.456, 0.406]\nstd= [0.229, 0.224, 0.225]\n\ncompose = transforms.Compose([transforms.Resize((256,256)),\n                              transforms.CenterCrop(224),\n                             transforms.ToTensor(),\n                             transforms.Normalize(mean,std)])\ntrain_set = Dog_data(training_df, transform=compose)\nval_set = Dog_data(validation_df, transform=compose)\ntest_set = Dog_data(test_df, transform=compose, test=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the dataset\nplt.subplots()\nplt.imshow(test_set[0].permute(1,2,0))\nplt.subplots()\nplt.imshow(train_set[0][0].permute(1,2,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now the dataset is ready, time to create the model and other stuff","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare all the stuff\n- GPU\n- Data loader for training set ,validation set, test set\n- Model - suing Resnet50\n- Optimizer - SGD with momentum\n- Cost function - CrossEntropy\n- Training function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GPU\nprint(torch.cuda.is_available())\ndevice = torch.device('cuda:0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\n# disable the tuning of parameter in model\nfor param in model.parameters():\n    param.requires_grad=False\n    \n# Modify the output layer\nmodel.fc= nn.Linear(in_features=2048, out_features=120, bias=True)\n\n# Transfer to GPU\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dataset loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset=train_set, batch_size=32)\nval_loader = DataLoader(dataset=val_set, batch_size=64)\ntest_loader = DataLoader(dataset=test_set,batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Optimizer and Cost function"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0003\n\ncost_function = nn.CrossEntropyLoss()\n\nparams = [param for param in model.parameters() if param.requires_grad]\noptimizer = torch.optim.SGD(params, lr=learning_rate,momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Training function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of validation set\nn_val = len(val_set)\n\ndef train_model(model, train, validation, optimizer, cost_function, epochs=10, patience=5):\n    train_cost_list = [] # Store the cost of training set\n    val_cost_list = [] # Store the cost of validation set\n    accuracy_list = [] # Store the accuarcy of validation set\n\n    for epoch in range(epochs):\n        train_cost_sublist = []\n        print('Start training....{}/{} epochs'.format(epoch+1, epochs))\n        for x,y in train:\n            x,y = x.to(device),y.to(device)\n            model.train() # Activate training mode\n            optimizer.zero_grad()\n            z = model(x)\n            loss = cost_function(z,y)\n            train_cost_sublist.append(loss.item())\n            loss.backward()\n            optimizer.step()\n        train_cost_list.append(np.mean(train_cost_sublist))\n        \n        correct = 0\n        val_cost_sublist = []\n        for x_val, y_val in validation:\n            model.eval() # Actiavte evaluation mode\n            x_val,y_val = x_val.to(device),y_val.to(device)\n            z = model(x_val)\n            loss = cost_function(z,y_val)\n            val_cost_sublist.append(loss.item())\n            _,yhat = torch.max(z.data,1)\n            correct = correct + (yhat==y_val).sum().item()\n        val_cost_list.append(np.mean(val_cost_sublist))\n        \n        # Count accuarcy\n        accuracy = correct/n_val\n        accuracy_list.append(accuracy)\n        \n        print('Training loss: {:.3f}, Validation loss: {:.3f}, Accuracy: {:.3f}'.format(np.mean(train_cost_sublist),\n                                                                                        np.mean(val_cost_sublist),\n                                                                                        accuracy))\n        # Early stopping\n        if epoch+1 >= 10: # Start when model is training for more than 10 epochs\n            growth_list = []\n            this_turn_acc = accuracy_list[-1]\n            for i in range(patience):\n                growth = this_turn_acc - accuracy_list[-1-(i+1)]\n                if growth>0.001:\n                    growth_list.append(growth)\n            if len(growth_list) ==0:\n                print('Early stopped.')\n                print('Finish training.')\n                break\n            \n    print('Finish training.')\n    return (train_cost_list,val_cost_list, accuracy_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cost,val_cost, acc = train_model(model,train_loader,val_loader,optimizer, cost_function, epochs=50,patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the cost\ndef plot_cost(train, validation):\n    plt.plot(train, label='Training Loss',color='blue')\n    plt.plot(validation, label='validation Loss',color='orange')\n    plt.title(\"Training Loss vs Validation Loss\")\n    plt.xlabel('iteration')\n    plt.ylabel('loss')\n    plt.legend()\n    plt.grid('on')\n    plt.show\n    \nplot_cost(train_cost,val_cost)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"answer_id = answer_df.id.tolist()\nanswer_prediction = []\nmodel.eval()\nfor image in test_loader:\n    image = image.to(device)\n    model.eval()\n    y_pred = model(image)\n    answer = y_pred[0].cpu().detach().numpy().T.tolist()\n    answer_prediction.append(answer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the answer in dataframe, set the file name to index\nanswer_prediction = pd.DataFrame(answer_prediction)\nanswer_prediction['id'] = answer_id\nanswer_prediction = answer_prediction.set_index('id',drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the breed name <--> index dictionary\nmatch_id_df = match_id_df.drop_duplicates(subset='breed_label')\nmatch_id_df = match_id_df.set_index('breed_label',drop=True)\nid_dict = match_id_df.to_dict()\nid_dict = id_dict['breed'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the dataframe column name from index to breed name\nprediction = answer_prediction.copy()\nprediction.columns = answer_prediction.columns.map(id_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the prediction\nprediction.to_csv('answer.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fix the problem\n- Apply softmax() to the output"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn.functional import softmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer_csv = pd.read_csv('./answer.csv')\nfinal_prediction = answer_csv.copy()\nfinal_prediction.set_index('id',drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(final_prediction.shape[0]):\n    proba_row = softmax(torch.Tensor(answer_csv.iloc[i][1:].tolist()))\n    proba_row = proba_row.tolist()\n    final_prediction.iloc[i] = proba_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_prediction.to_csv('answer02.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}